Error: context_length_exceeded
The maximum context length for this model is 200000 tokens.
Conversation too long; context was truncated.
